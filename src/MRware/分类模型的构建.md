# 模型设计思路

## 网络架构选择与优化

**预训练模型基础**

- **EfficientNet-B4/B5**：在ImageNet上预训练，参数效率高，适合菜品细粒度分类
- **ResNet-152/ResNeXt-101**：深层网络，特征提取能力强
- **Vision Transformer (ViT)**：注意力机制对菜品细节识别效果好
- **ConvNeXt**：结合CNN和Transformer优势的现代架构

**多尺度特征融合**

```python
# 示例：多尺度特征提取
class MultiscaleFoodNet(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.backbone = timm.create_model('efficientnet_b4', pretrained=True)
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.local_pool = nn.AdaptiveMaxPool2d(1)
        self.classifier = nn.Linear(1792*2, num_classes)
        
    def forward(self, x):
        features = self.backbone.forward_features(x)
        global_feat = self.global_pool(features).flatten(1)
        local_feat = self.local_pool(features).flatten(1)
        combined = torch.cat([global_feat, local_feat], dim=1)
        return self.classifier(combined)
```

## 损失函数设计

**Focal Loss**

- 解决类别不平衡问题
- 专注于困难样本的学习

```python
class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()
```

**Label Smoothing**

- 防止过拟合，提高泛化能力
- 对于相似菜品（如不同做法的鱼）特别有效

**Center Loss**

- 增加类内聚合度，提高特征判别性
- 适合菜品间细微差异的识别

## 数据增强策略

**几何变换增强**

```python
transform_train = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),
])
```

**高级增强技术**

- **CutMix/MixUp**：混合不同图像，提高泛化能力
- **AutoAugment**：自动搜索最优增强策略
- **AugMax**：针对食物图像的专门增强

## 注意力机制集成

**通道注意力（SE/CBAM）**

```python
class SEBlock(nn.Module):
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.squeeze = nn.AdaptiveAvgPool2d(1)
        self.excitation = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.squeeze(x).view(b, c)
        y = self.excitation(y).view(b, c, 1, 1)
        return x * y
```

**空间注意力**

- 关注菜品的关键区域（形状、颜色、纹理）
- 忽略背景干扰

## 模型集成策略

**多模型投票**

```python
models = [efficientnet_b4, resnet152, vit_base]
predictions = []
for model in models:
    pred = model(input_image)
    predictions.append(F.softmax(pred, dim=1))

ensemble_pred = torch.mean(torch.stack(predictions), dim=0)
```

**知识蒸馏**

- 用大模型指导小模型学习
- 保持精度的同时提升推理速度

## 训练策略优化

**学习率调度**

- Cosine Annealing with Restart
- 在训练后期进行fine-tuning

**渐进式训练**

```python
# 第一阶段：冻结backbone，只训练分类头
for param in model.backbone.parameters():
    param.requires_grad = False

# 第二阶段：解冻所有层，低学习率训练
for param in model.parameters():
    param.requires_grad = True
optimizer = optim.Adam(model.parameters(), lr=1e-5)
```

**正则化技术**

- Dropout (0.3-0.5)
- Weight Decay (1e-4)
- Early Stopping

## 针对菜品特点的优化

**多任务学习**

- 同时预测菜品类别和属性（口味、烹饪方法、主料）
- 共享特征表示，提高泛化能力

**层次化分类**

- 先分大类（中式、西式、日式）
- 再细分具体菜品
- 减少错误分类的影响

**区域特征学习**

- 使用目标检测预处理，裁剪菜品主体
- 减少餐具、背景干扰

# 开发流程

## 1. 数据准备阶段

**数据收集**

- 收集原始图像数据（测试训练使用food101数据集）
- 确保数据的多样性和代表性
- 考虑不同光照、角度、背景条件

**数据预处理**

- 图像尺寸统一（通常resize到224x224或更高）
- 数据清洗，去除低质量图像
- 标注质量检查和修正

**数据划分**

- 训练集（70-80%）
- 验证集（10-15%）
- 测试集（10-15%）
- 确保各类别分布均衡

## 2. 模型构建阶段

**架构设计**

- 选择合适的基础网络（ResNet、EfficientNet等）
- 设计分类头结构
- 添加正则化组件（Dropout、BatchNorm）

**超参数初始化**

- 学习率、批量大小、优化器选择
- 损失函数设计
- 训练轮数规划

## 3. 预训练阶段

**迁移学习准备**

- 加载在ImageNet上预训练的权重
- 冻结backbone参数
- 只训练分类头

**初步训练**

```python
# 冻结预训练层
for param in model.backbone.parameters():
    param.requires_grad = False

# 只训练分类器
optimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)
```

## 4. 微调阶段（Fine-tuning）

**解冻训练**

- 解冻部分或全部预训练层
- 使用较小的学习率
- 逐层或分组解冻

**学习率策略**

```python
# 不同层使用不同学习率
optimizer = optim.Adam([
    {'params': model.backbone.parameters(), 'lr': 1e-5},
    {'params': model.classifier.parameters(), 'lr': 1e-3}
])
```

## 5. 正式训练阶段

**完整训练**

- 使用完整的训练策略
- 应用数据增强
- 监控训练和验证指标

**动态调整**

- 学习率调度（StepLR、CosineAnnealingLR）
- 根据验证集表现调整超参数
- Early stopping防止过拟合

## 6. 验证调优阶段

**超参数调优**

- 网格搜索或贝叶斯优化
- 交叉验证
- 模型选择和比较

**性能分析**

- 混淆矩阵分析
- 类别准确率统计
- 错误样本分析

## 7. 测试评估阶段

**最终评估**

- 在测试集上评估模型性能
- 计算各项指标（准确率、F1-score、Top-5准确率）
- 生成分类报告

**鲁棒性测试**

- 对抗样本测试
- 不同数据分布的泛化能力
- 边界情况处理

## 8. 部署优化阶段

**模型压缩**

- 量化（INT8）
- 剪枝
- 知识蒸馏

**推理优化**

- 模型格式转换（ONNX、TensorRT）
- 批处理优化
- 内存使用优化

## 关键监控指标

**训练过程监控**

- 训练损失和验证损失
- 训练准确率和验证准确率
- 学习率变化
- 梯度范数

**过拟合检测**

- 训练验证损失差距
- 验证准确率plateau
- 模型复杂度分析

# 部署训练

```
pip install torch torchvision timm opencv-python pillow matplotlib scikit-learn seaborn tqdm
```

## 1.二次改进代码

```
# 设置GPU和多线程
def setup_device():
    """设置设备和优化GPU使用"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f'Using GPU: {torch.cuda.get_device_name(0)}')
        print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
        
        # 启用cudnn优化
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        # 设置GPU内存分配策略
        torch.cuda.empty_cache()
    else:
        device = torch.device('cpu')
        print('Using CPU')
    
    return device

# =================== 优化的数据加载器 ===================
def get_optimized_dataloader(dataset, batch_size=32, shuffle=True, num_workers=4):
    """获取优化的数据加载器"""
    return DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=shuffle, 
        num_workers=num_workers,
        pin_memory=True,  # 加速GPU数据传输
        persistent_workers=True,  # 保持worker进程
        prefetch_factor=2,  # 预取因子
        drop_last=True if shuffle else False  # 训练时丢弃最后一个不完整batch
    )

# =================== 改进的训练器类 ===================
class OptimizedFoodRecognitionTrainer:
    def __init__(self, model, train_loader, val_loader, device, num_classes=10):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.num_classes = num_classes
        
        # 使用混合精度训练
        self.scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None
        
        # 损失函数
        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
        
        # 优化器 - 使用更好的学习率
        self.optimizer = optim.AdamW(
            model.parameters(), 
            # lr=1e-3, 
            weight_decay=1e-4,
            eps=1e-8
        )
        
        # 学习率调度器
        self.scheduler = optim.lr_scheduler.OneCycleLR(
            self.optimizer,
            # max_lr=1e-3,
            # steps_per_epoch=len(train_loader),
            # epochs=50,
            pct_start=0.3,
            div_factor=10,
            final_div_factor=100
        )
    
    def train_epoch(self):
        """训练一个epoch"""
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        pbar = tqdm(self.train_loader, desc='Training')
        for batch_idx, (data, target) in enumerate(pbar):
            # 非阻塞传输到GPU
            data = data.to(self.device, non_blocking=True)
            target = target.to(self.device, non_blocking=True)
            
            self.optimizer.zero_grad()
            
            # 混合精度训练
            if self.scaler:
                with torch.cuda.amp.autocast():
                    output = self.model(data)
                    loss = self.criterion(output, target)
                
                self.scaler.scale(loss).backward()
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                output = self.model(data)
                loss = self.criterion(output, target)
                loss.backward()
                self.optimizer.step()
            
            # 更新学习率
            self.scheduler.step()
            
            total_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
            
            pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{100.*correct/total:.2f}%',
                'LR': f'{self.scheduler.get_last_lr()[0]:.6f}'
            })
            
            # 定期清理GPU缓存
            if batch_idx % 100 == 0:
                torch.cuda.empty_cache()
        
        avg_loss = total_loss / len(self.train_loader)
        accuracy = 100. * correct / total
        return avg_loss, accuracy
    
    def validate(self):
        """验证模型"""
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in tqdm(self.val_loader, desc='Validation'):
                data = data.to(self.device, non_blocking=True)
                target = target.to(self.device, non_blocking=True)
                
                # 混合精度推理
                if self.scaler:
                    with torch.cuda.amp.autocast():
                        output = self.model(data)
                        loss = self.criterion(output, target)
                else:
                    output = self.model(data)
                    loss = self.criterion(output, target)
                
                total_loss += loss.item()
                _, predicted = output.max(1)
                total += target.size(0)
                correct += predicted.eq(target).sum().item()
        
        avg_loss = total_loss / len(self.val_loader)
        accuracy = 100. * correct / total
        return avg_loss, accuracy
    
    def train(self, epochs=50):
        
        for epoch in range(epochs):
            print(f'\nEpoch {epoch+1}/{epochs}')
            print('-' * 50)
            
            # 训练
            train_loss, train_acc = self.train_epoch()
            
            # 验证
            val_loss, val_acc = self.validate()
            
            # 记录
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            self.val_accuracies.append(val_acc)
            
            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')
            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')
            
            
            # 监控GPU内存使用
            if self.device.type == 'cuda':
                memory_allocated = torch.cuda.memory_allocated(self.device) / 1024**3
                memory_reserved = torch.cuda.memory_reserved(self.device) / 1024**3
                print(f'GPU Memory: {memory_allocated:.1f}GB allocated, {memory_reserved:.1f}GB reserved')
```

### 主要改进点

**1. GPU优化**

- 添加了混合精度训练 (`torch.cuda.amp`)
- 使用 `non_blocking=True` 加速数据传输
- 启用 `cudnn.benchmark` 优化
- 定期清理GPU缓存

**2. 数据加载优化**

- 使用 `pin_memory=True` 加速GPU传输
- 添加 `persistent_workers=True` 保持worker进程
- 设置预取因子 `prefetch_factor=2`

**3. 训练策略改进**

- 使用 `OneCycleLR` 学习率调度器
- 添加Label Smoothing
- 改进的checkpoint保存机制

**4. 内存管理**

- 监控GPU内存使用
- 定期清理GPU缓存
- 优化batch处理

## 2.参数调整

根据GPU显存大小可以修改batch_size

8GB显存：batch_size=16-24

12GB显存：batch_size=32-48

24GB显存：batch_size=64+

## 3.数据集设置

```
data/
├── train/
│   ├── class1/
│   └── class2/
├── val/
└── test/
```

